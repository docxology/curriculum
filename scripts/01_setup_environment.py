#!/usr/bin/env python3
"""01 - Environment setup and validation.

This script performs comprehensive environment validation including:
- System information reporting
- Dependency checking
- Configuration validation
- Output directory structure
- Ollama service and model availability
"""

from __future__ import annotations

import sys
from pathlib import Path

# Add project root to Python path to allow imports when run directly
_script_dir = Path(__file__).resolve().parent
_project_root = _script_dir.parent
if str(_project_root) not in sys.path:
    sys.path.insert(0, str(_project_root))

import argparse
import logging
import platform
import shutil
from typing import Dict, List, Tuple

from src.config.loader import ConfigLoader
from src.utils.helpers import (
    ensure_model_available,
    ollama_is_running,
    run_cmd_capture,
)
from src.utils.logging_setup import (
    setup_logging, 
    log_info_box,
)

import yaml


def parse_args() -> argparse.Namespace:
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description="Environment setup and validation.",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s                          # Basic validation
  %(prog)s --auto-install           # Install dependencies if needed
  %(prog)s --start-ollama           # Start Ollama if not running
  %(prog)s --verbose                # Detailed logging
        """,
    )
    parser.add_argument(
        "--config-dir",
        type=Path,
        default=Path(__file__).parent.parent / "config",
        help="Path to config directory (default: ../config)",
    )
    parser.add_argument(
        "--auto-install",
        action="store_true",
        help="Install project dependencies with uv if needed.",
    )
    parser.add_argument(
        "--start-ollama",
        action="store_true",
        help="Attempt to start ollama serve if not running.",
    )
    parser.add_argument(
        "--verbose",
        "-v",
        action="store_true",
        help="Enable verbose logging output.",
    )
    return parser.parse_args()


def report_system_info(logger: logging.Logger) -> Dict[str, str]:
    """Report comprehensive system information.
    
    Args:
        logger: Logger instance for output
        
    Returns:
        Dictionary of system information
    """
    system_info = {
        "Python Version": f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}",
        "Python Executable": sys.executable,
        "Platform": platform.platform(),
        "OS": platform.system(),
        "Architecture": platform.machine(),
        "Hostname": platform.node(),
        "Repository Root": str(Path(__file__).parent.parent),
    }
    
    # Add disk space info
    try:
        usage = shutil.disk_usage(Path.cwd())
        system_info["Disk Free"] = f"{usage.free / (1024**3):.1f} GB"
        system_info["Disk Usage"] = f"{(usage.used / usage.total * 100):.1f}%"
    except Exception as exc:
        logger.debug(f"Could not get disk usage: {exc}")
    
    log_info_box(logger, "System Information", system_info, emoji="üíª")
    
    return system_info


def check_tool_availability(logger: logging.Logger) -> Tuple[bool, Dict[str, str]]:
    """Check availability of required and optional tools.
    
    Args:
        logger: Logger instance for output
        
    Returns:
        Tuple of (all_required_available, tool_versions)
    """
    tools = {
        "uv": {"required": True, "cmd": ["uv", "--version"]},
        "python3": {"required": True, "cmd": ["python3", "--version"]},
        "git": {"required": False, "cmd": ["git", "--version"]},
        "ollama": {"required": False, "cmd": ["ollama", "--version"]},
    }
    
    tool_versions = {}
    all_required_available = True
    
    logger.info("")
    logger.info("üîß Tool Availability")
    logger.info("‚îÄ" * 60)
    
    for tool_name, info in tools.items():
        result = run_cmd_capture(info["cmd"])
        available = result.returncode == 0
        
        if available:
            version = result.stdout.strip().split("\n")[0] if result.stdout else "available"
            tool_versions[tool_name] = version
            logger.info(f"  ‚úÖ {tool_name:.<18} {version}")
        else:
            tool_versions[tool_name] = "NOT FOUND"
            if info["required"]:
                logger.error(f"  ‚ùå {tool_name:.<18} NOT FOUND (required)")
                all_required_available = False
            else:
                logger.warning(f"  ‚ö†Ô∏è  {tool_name:.<18} NOT FOUND (optional)")
    
    logger.info("‚îÄ" * 60)
    return all_required_available, tool_versions


def validate_configurations(
    config_dir: Path, 
    logger: logging.Logger
) -> Tuple[bool, ConfigLoader, Dict[str, int]]:
    """Validate all configuration files and report details.
    
    Args:
        config_dir: Path to configuration directory
        logger: Logger instance for output
        
    Returns:
        Tuple of (success, config_loader, config_stats)
    """
    logger.info("")
    logger.info("‚öôÔ∏è  Configuration Validation")
    logger.info("‚îÄ" * 60)
    logger.info(f"  üìÅ Config directory: {config_dir}")
    logger.info("")
    
    config_stats = {}
    
    try:
        # Check configuration files exist
        config_files = {
            "course_config.yaml": "Course structure",
            "llm_config.yaml": "LLM settings",
            "output_config.yaml": "Output paths",
        }
        
        logger.info("  üìÑ Configuration Files:")
        for filename, description in config_files.items():
            filepath = config_dir / filename
            if filepath.exists():
                size = filepath.stat().st_size
                logger.info(f"    ‚úÖ {filename:.<25} {description:.<15} ({size:>5,} bytes)")
            else:
                logger.error(f"    ‚ùå {filename:.<25} NOT FOUND")
                logger.info("‚îÄ" * 60)
                return False, None, config_stats
        
        # Load and validate
        config_loader = ConfigLoader(config_dir)
        config_loader.validate_all_configs()
        logger.info("  ‚úÖ All configurations validated")
        logger.info("")
        
        # Report configuration details
        course_info = config_loader.get_course_info()
        modules = config_loader.get_modules()
        config_stats["module_count"] = len(modules) if modules else 0
        
        # Report course info (concise)
        logger.info("  üìö Course Information:")
        logger.info(f"    ‚Ä¢ Course: {course_info.get('name', 'Unknown')}")
        logger.info(f"    ‚Ä¢ Level:  {course_info.get('level', 'Unknown')}")
        logger.info(f"    ‚Ä¢ Modules loaded: {len(modules) if modules else 0}")
        logger.info("")
        
        # LLM configuration
        llm_params = config_loader.get_llm_parameters()
        config_stats["llm_model"] = llm_params.get("model", "unknown")
        config_stats["llm_temperature"] = llm_params.get("temperature", 0.0)
        # Get num_predict from parameters (Ollama uses num_predict, not max_tokens)
        parameters = llm_params.get("parameters", {})
        config_stats["llm_max_tokens"] = parameters.get("num_predict", 0)
        
        logger.info("  ü§ñ LLM Configuration:")
        logger.info(f"    ‚Ä¢ Model: {llm_params.get('model', 'not specified')}")
        temp = parameters.get('temperature', 'default')
        tokens = parameters.get('num_predict', 'default')
        logger.info(f"    ‚Ä¢ Temperature: {temp}, Max Tokens: {tokens}")
        logger.info("")
        
        # Output configuration (summary only)
        output_config = config_loader.get_output_paths()
        base_dir = output_config.get("base_directory", "output")
        directories = output_config.get("directories", {})
        config_stats["output_directory_count"] = len(directories)
        logger.info(f"  üìÇ Output base: {base_dir} ({len(directories)} directories)")
        
        logger.info("‚îÄ" * 60)
        return True, config_loader, config_stats
        
    except Exception as exc:
        logger.error(f"  ‚ùå Configuration validation failed: {exc}")
        logger.info("‚îÄ" * 60)
        return False, None, config_stats


def setup_output_structure(
    config_dir: Path, 
    logger: logging.Logger,
    course_name: Optional[str] = None
) -> Tuple[bool, List[Path]]:
    """Ensure output directory structure exists.
    
    Args:
        config_dir: Path to configuration directory
        logger: Logger instance for output
        course_name: Optional course template name for course-specific directories
        
    Returns:
        Tuple of (success, created_directories)
    """
    logger.info("")
    logger.info("üìÇ Output Directory Structure")
    logger.info("‚îÄ" * 60)
    
    try:
        with open(config_dir / "output_config.yaml", "r", encoding="utf-8") as f:
            output_config = yaml.safe_load(f).get("output", {})
        base = Path(output_config.get("base_directory", "output"))
        directories = output_config.get("directories", {})
        
        created_dirs = []
        
        # Create base directory
        if not base.exists():
            base.mkdir(parents=True, exist_ok=True)
            logger.info(f"  ‚úÖ Created base: {base}")
            created_dirs.append(base)
        else:
            logger.info(f"  ‚úÖ Base exists: {base}")
        
        # Determine target directory (course-specific or default)
        if course_name:
            target_base = base / course_name
            logger.info(f"  üìÅ Course-specific directory: {course_name}/")
        else:
            target_base = base
            logger.info(f"  üìÅ Default directory structure")
        
        # Create subdirectories (compact view)
        for name, subdir in sorted(directories.items()):
            if course_name:
                # Course-specific: output/{course_name}/{subdir}
                dir_path = target_base / subdir
            else:
                # Default: output/{subdir}
                dir_path = base / subdir
            
            if not dir_path.exists():
                dir_path.mkdir(parents=True, exist_ok=True)
                display_path = f"{course_name}/{subdir}" if course_name else subdir
                logger.info(f"  ‚úÖ Created: {name:.<18} ‚Üí {display_path}")
                created_dirs.append(dir_path)
            else:
                # Count existing files
                file_count = len(list(dir_path.glob("*")))
                display_path = f"{course_name}/{subdir}" if course_name else subdir
                if file_count > 0:
                    logger.info(f"  ‚úÖ Exists:  {name:.<18} ‚Üí {display_path} ({file_count} files)")
                else:
                    logger.info(f"  ‚úÖ Exists:  {name:.<18} ‚Üí {display_path}")
        
        logger.info("")
        logger.info(f"  üìä Total directories: {len(directories) + 1} (created: {len(created_dirs)})")
        logger.info("‚îÄ" * 60)
        
        return True, created_dirs
        
    except Exception as exc:
        logger.error(f"  ‚ùå Failed to setup output structure: {exc}")
        logger.info("‚îÄ" * 60)
        return False, []


def check_ollama_status(
    config_loader: ConfigLoader,
    logger: logging.Logger,
    start_if_needed: bool = False,
) -> Tuple[bool, Dict[str, any]]:
    """Check Ollama service status and model availability.
    
    Args:
        config_loader: ConfigLoader instance
        logger: Logger instance for output
        start_if_needed: Whether to attempt starting Ollama if not running
        
    Returns:
        Tuple of (ollama_ready, status_info)
    """
    logger.info("")
    logger.info("ü§ñ Ollama Service Status")
    logger.info("‚îÄ" * 60)
    
    status_info = {
        "running": False,
        "configured_model_available": False,
        "available_models": [],
    }
    
    # Check if Ollama is running
    if ollama_is_running():
        logger.info("  ‚úÖ Service is running")
        status_info["running"] = True
    else:
        logger.warning("  ‚ùå Service is NOT running")
        
        if start_if_needed:
            logger.info("  üîÑ Attempting to start Ollama service...")
            run_cmd_capture(["ollama", "serve"])
            
            if ollama_is_running():
                logger.info("  ‚úÖ Service started successfully")
                status_info["running"] = True
            else:
                logger.error("  ‚ùå Failed to start service")
                logger.error("  üí° Please start manually: ollama serve")
                logger.info("‚îÄ" * 60)
                return False, status_info
        else:
            logger.warning("  üí° Run with --start-ollama to attempt auto-start")
            logger.warning("  üí° Or start manually: ollama serve")
            logger.info("‚îÄ" * 60)
            return False, status_info
    
    # List available models
    logger.info("  üìã Checking available models...")
    list_result = run_cmd_capture(["ollama", "list"])
    
    if list_result.returncode == 0 and list_result.stdout:
        lines = list_result.stdout.strip().split("\n")
        if len(lines) > 1:  # Skip header
            models = []
            for line in lines[1:]:
                parts = line.split()
                if parts:
                    model_name = parts[0]
                    models.append(model_name)
                    logger.info(f"    ‚Ä¢ {model_name}")
            status_info["available_models"] = models
            logger.info(f"  üìä Total models: {len(models)}")
        else:
            logger.warning("  ‚ö†Ô∏è  No models found")
    else:
        logger.warning("  ‚ö†Ô∏è  Could not list models")
    
    logger.info("")
    # Check configured model
    configured_model = config_loader.get_llm_parameters().get("model", "llama3")
    logger.info(f"  üéØ Configured model: {configured_model}")
    
    if ensure_model_available(configured_model):
        logger.info(f"  ‚úÖ Model '{configured_model}' is available")
        status_info["configured_model_available"] = True
    else:
        logger.warning(f"  ‚ùå Model '{configured_model}' NOT FOUND")
        logger.warning(f"  üí° Run: ollama pull {configured_model}")
        status_info["configured_model_available"] = False
    
    # Check GPU usage
    logger.info("")
    logger.info("  üéÆ Checking GPU acceleration...")
    from src.utils.helpers import check_ollama_gpu_usage
    gpu_info = check_ollama_gpu_usage()
    if gpu_info["models_loaded"]:
        if gpu_info["using_gpu"]:
            logger.info(f"  ‚úÖ GPU acceleration active: {gpu_info['processor_info']}")
            status_info["gpu_active"] = True
        else:
            logger.warning(f"  ‚ö†Ô∏è  CPU-only mode detected: {gpu_info['processor_info']}")
            logger.warning("  üí° Generation will be slower. Check Ollama Metal support.")
            status_info["gpu_active"] = False
    else:
        logger.info("  ‚ÑπÔ∏è  No models currently loaded (GPU check requires active model)")
        logger.info("  üí° GPU will be verified when model is first used")
        status_info["gpu_active"] = None  # Unknown - no models loaded
    
    logger.info("‚îÄ" * 60)
    return status_info["running"] and status_info["configured_model_available"], status_info


def print_summary(
    logger: logging.Logger,
    success: bool,
    system_info: Dict[str, str],
    tool_versions: Dict[str, str],
    config_stats: Dict[str, any],
    ollama_status: Dict[str, any],
) -> None:
    """Print comprehensive summary of environment setup.
    
    Args:
        logger: Logger instance for output
        success: Overall success status
        system_info: System information dictionary
        tool_versions: Tool version information
        config_stats: Configuration statistics
        ollama_status: Ollama status information
    """
    logger.info("")
    logger.info("üìä ENVIRONMENT SETUP SUMMARY")
    logger.info("‚îÄ" * 60)
    
    # Overall status
    status_emoji = "‚úÖ" if success else "‚ùå"
    status_text = "READY" if success else "INCOMPLETE"
    logger.info(f"{status_emoji} Overall Status: {status_text}")
    logger.info("")
    
    # System
    logger.info("üíª System:")
    logger.info(f"  ‚Ä¢ Python: {system_info.get('Python Version', 'unknown')}")
    logger.info(f"  ‚Ä¢ Platform: {system_info.get('Platform', 'unknown')[:50]}")
    logger.info(f"  ‚Ä¢ Disk Free: {system_info.get('Disk Free', 'unknown')}")
    logger.info("")
    
    # Tools
    logger.info("üîß Tools:")
    for tool, version in tool_versions.items():
        status_emoji = "‚úÖ" if version != "NOT FOUND" else "‚ùå"
        display_version = version[:50] if len(version) > 50 else version
        logger.info(f"  {status_emoji} {tool}: {display_version}")
    logger.info("")
    
    # Configuration
    logger.info("‚öôÔ∏è  Configuration:")
    logger.info(f"  ‚Ä¢ Modules: {config_stats.get('module_count', 0)}")
    logger.info(f"  ‚Ä¢ LLM Model: {config_stats.get('llm_model', 'unknown')}")
    logger.info(f"  ‚Ä¢ Output Directories: {config_stats.get('output_directory_count', 0)}")
    logger.info("")
    
    # Ollama
    logger.info("ü§ñ Ollama:")
    ollama_running_emoji = "‚úÖ" if ollama_status.get("running") else "‚ùå"
    ollama_running_text = "Running" if ollama_status.get("running") else "Not Running"
    logger.info(f"  {ollama_running_emoji} Service: {ollama_running_text}")
    logger.info(f"  üìä Available Models: {len(ollama_status.get('available_models', []))}")
    model_ready_emoji = "‚úÖ" if ollama_status.get("configured_model_available") else "‚ùå"
    model_ready_text = "Available" if ollama_status.get("configured_model_available") else "Not Available"
    logger.info(f"  {model_ready_emoji} Configured Model: {model_ready_text}")
    logger.info("‚îÄ" * 60)
    logger.info("")
    
    if success:
        logger.info("‚úÖ Environment is ready for validation and testing")
        logger.info("  üí° Next step: uv run python3 scripts/02_run_tests.py")
    else:
        logger.warning("‚ö†Ô∏è  Environment setup incomplete - address issues above")


def main() -> int:
    """Main entry point for environment setup script.
    
    Returns:
        Exit code (0 for success, 1 for failure)
    """
    args = parse_args()
    
    # Setup logging with file output
    log_level = "DEBUG" if args.verbose else "INFO"
    log_file = setup_logging(
        script_name="01_setup_environment",
        log_level=log_level,
        console_output=True,
        file_output=True
    )
    
    logger = logging.getLogger("setup_environment")
    
    logger.info("")
    logger.info("üîß EDUCATIONAL COURSE GENERATOR - ENVIRONMENT SETUP")
    logger.info("‚îÄ" * 60)
    if log_file:
        logger.info(f"üìù Log file: {log_file}")
    logger.info("")
    
    # Track overall success
    overall_success = True
    
    # System information
    system_info = report_system_info(logger)
    logger.info("")
    
    # Tool availability
    tools_available, tool_versions = check_tool_availability(logger)
    if not tools_available:
        logger.error("Required tools are missing - cannot continue")
        return 1
    logger.info("")
    
    # Optional dependency install
    if args.auto_install:
        logger.info("")
        logger.info("üì¶ Installing Dependencies")
        logger.info("‚îÄ" * 60)
        logger.info("  üîÑ Running: uv pip install -e .[dev]")
        install_result = run_cmd_capture(
            ["uv", "pip", "install", "-e", ".[dev]"],
            cwd=Path(__file__).parent.parent,
        )
        if install_result.returncode == 0:
            logger.info("  ‚úÖ Dependencies installed successfully")
        else:
            logger.error("  ‚ùå Dependency installation failed")
            logger.error(f"  {install_result.stderr}")
            overall_success = False
        logger.info("‚îÄ" * 60)
        logger.info("")
    
    # Configuration validation
    config_valid, config_loader, config_stats = validate_configurations(
        args.config_dir, logger
    )
    if not config_valid:
        logger.error("Configuration validation failed - cannot continue")
        return 1
    logger.info("")
    
    # Output structure
    output_success, created_dirs = setup_output_structure(args.config_dir, logger)
    if not output_success:
        logger.warning("Output structure setup had issues")
        overall_success = False
    logger.info("")
    
    # Ollama status
    ollama_ready, ollama_status = check_ollama_status(
        config_loader, logger, args.start_ollama
    )
    if not ollama_ready:
        logger.warning("Ollama is not fully ready")
        overall_success = False
    logger.info("")
    
    # Summary
    print_summary(
        logger,
        overall_success,
        system_info,
        tool_versions,
        config_stats,
        ollama_status,
    )
    
    return 0 if overall_success else 1


if __name__ == "__main__":
    sys.exit(main())


