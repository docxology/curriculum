# Introduction to Bayesian Statistics - Study Notes

## Key Concepts

## Introduction to Bayesian Statistics – Study Notes

**Probability**: Probability (probability: The numerical measure of the likelihood of an event occurring, ranging from 0 (impossible) to 1 (certain)). It’s a fundamental concept in statistics, providing a framework for quantifying uncertainty. We represent probabilities using numbers between 0 and 1. A probability of 0 indicates an event is impossible, while a probability of 1 signifies the event is certain. For example, the probability of flipping a fair coin and getting heads is 0.5. Similarly, the probability of rolling a 3 on a fair six-sided die is 1/6. Crucially, probability doesn’t predict the exact outcome; it expresses the *relative* likelihood of different outcomes.

**Uniform Distribution**: Uniform Distribution (uniform distribution: A probability distribution where every value within a given range has an equal chance of occurring).  Imagine a number line from 0 to 1. The uniform distribution assigns an equal probability to all numbers within that range. This contrasts with distributions where some values are more likely than others.  For instance, if we were to estimate a person's height, the height would likely not follow a uniform distribution – taller people are, on average, taller. The uniform distribution is most useful when there's no prior knowledge about the distribution of a variable. It’s often used as a starting point for Bayesian analysis.

**Sample Space**: Sample Space (sample space: The set of all possible outcomes of a random experiment).  Consider rolling a die. The sample space is {1, 2, 3, 4, 5, 6}. Each element in the set represents a possible outcome. The size of the sample space depends on the number of possible outcomes.  Understanding the sample space is the first step in any probabilistic analysis.

**Probability Distributions**: Probability Distributions (probability distribution: A function that describes the likelihood of different outcomes in a probability experiment). These are mathematical functions that show the probability of each possible outcome in a random event.  Different types of distributions exist, such as the normal distribution (bell curve), the binomial distribution (counts of successes in multiple trials), and the Poisson distribution (counts of events occurring in a fixed interval of time or space). Bayesian statistics heavily relies on understanding and utilizing these different distributions.

**Marginalization**: Marginalization (marginalization: The process of integrating out parameters from a joint probability distribution to obtain a marginal distribution). This is a key concept in Bayesian inference. It involves calculating the probability of a variable, ignoring the influence of other variables. For example, if we have a joint probability distribution for height and weight, marginalization would allow us to calculate the probability of a person's height without considering their weight. This is often achieved using Bayes' Theorem.

**Defining Probability**: Defining Probability (defining probability: Probability can be defined in several ways, most commonly as the ratio of favorable outcomes to total possible outcomes.  It is a measure of relative likelihood rather than absolute certainty).  This definition is the most intuitive and frequently used. It’s important to remember that probability deals with *relative* frequencies.  If we flip a coin many times, the probability of heads approaches 0.5 as the number of flips increases.