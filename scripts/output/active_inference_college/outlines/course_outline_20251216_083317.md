# Active Inference and Probabilistic Dynamical Systems - Course Outline

**Level**: Undergraduate
**Duration**: Not specified weeks
**Total Class Sessions**: 15
**Total Modules**: 15
**Generated**: 2025-12-16 08:33:17

---
## Course Description

A comprehensive undergraduate course on Active Inference, Bayesian statistics, and probabilistic dynamical 
perception-action systems. This course provides a thorough introduction to how biological and artificial systems 
use probabilistic reasoning, Bayesian inference, and active engagement with their environment to maintain 
adaptive behavior. Students will learn the mathematical foundations of Bayesian statistics, including probability 
theory, conditional probability, Bayes' theorem, and Bayesian inference. The course covers variational methods 
for approximate Bayesian inference, including variational free energy and its relationship to model evidence 
and surprise. Students will explore how these statistical principles apply to dynamical systems, where perception 
and action are coupled through generative models that make predictions about sensory inputs. The course examines 
how organisms and agents maintain their structural and functional integrity by minimizing variational free energy 
through both perceptual inference (updating beliefs about hidden states) and active inference (selecting actions 
that confirm predictions). Topics include the mathematical formulation of probabilistic state-space models, 
hierarchical generative models, temporal dynamics and Markov processes, the relationship between free energy 
minimization and Bayesian model selection, precision weighting and attention, policy selection and planning 
under uncertainty, and model learning through experience. The course connects these theoretical principles to 
concrete examples from neuroscience (e.g., predictive coding, sensorimotor control), cognitive science (e.g., 
perception, decision-making, learning), and artificial intelligence (e.g., Bayesian neural networks, 
reinforcement learning, autonomous agents). Students will gain hands-on experience through computational exercises 
implementing Bayesian inference, building generative models, simulating perception-action loops, and analyzing 
how probabilistic systems adapt to changing environments. The course emphasizes both mathematical rigor and 
intuitive understanding, with extensive use of examples, visualizations, and computational demonstrations to 
make abstract concepts concrete. Applications span from simple sensorimotor behaviors to complex cognitive 
processes, showing how probabilistic dynamical systems provide a unified framework for understanding adaptive 
behavior across scales of organization.


## Additional Constraints

Designed for science undergraduates with background in calculus, linear algebra, and basic probability. 
Emphasize building mathematical intuition through concrete examples and computational exercises. Progress 
from foundational Bayesian statistics to advanced topics in active inference and probabilistic dynamical 
systems. Include hands-on programming exercises implementing Bayesian inference, generative models, and 
perception-action simulations. Connect abstract mathematical principles to biological and cognitive phenomena. 
Provide extensive visualizations and intuitive explanations alongside formal derivations. Include practical 
applications in neuroscience, cognitive science, and artificial intelligence. Address both theoretical 
foundations and empirical evidence. Encourage critical thinking about the scope and limitations of 
probabilistic approaches to understanding adaptive systems.




## Module 1: Introduction to Bayesian Statistics

**Sessions**: 1

### Session 1: Probability Basics

**Subtopics:**
- Sample Space
- Probability Distributions
- Marginalization

**Learning Objectives:**
1. Define probability
2. Understand distributions

**Key Concepts:**
- Probability
- Uniform Distribution

**Rationale:** Sets the stage for Bayesian reasoning.

---

## Module 2: Conditional Probability & Bayes’ Theorem

**Sessions**: 1

### Session 2: Conditional Probability

**Subtopics:**
- Definition
- Chain Rule

**Learning Objectives:**
1. Calculate conditional probabilities

**Key Concepts:**
- Joint Probability

**Rationale:** Essential for updating beliefs.

---

## Module 3: Bayes’ Theorem – Derivation & Intuition

**Sessions**: 1

### Session 3: Bayes' Theorem Derivation

**Subtopics:**
- Conditional Probability revisited
- Derivation steps

**Learning Objectives:**
1. Understand the derivation

**Key Concepts:**
- Prior, Likelihood, Posterior

**Rationale:** Crucial for Bayesian inference.

---

## Module 4: Bayesian Inference – Model Specification

**Sessions**: 1

### Session 4: Model Selection Criteria

**Subtopics:**
- Likelihood ratio test
- AIC
- BIC

**Learning Objectives:**
1. Understand model comparison

**Key Concepts:**
- Model Evidence

**Rationale:** Selecting appropriate probabilistic frameworks.

---

## Module 5: Variational Inference – Introduction

**Sessions**: 1

### Session 5: The Challenge of Exact Inference

**Subtopics:**
- Computational Cost
- Approximation Methods

**Learning Objectives:**
1. Recognize the computational burden

**Key Concepts:**
- Surrogate Distributions

**Rationale:** Motivation for variational methods.

---

## Module 6: Variational Free Energy – Definition & Interpretation

**Sessions**: 1

### Session 6: Defining VFE

**Subtopics:**
- Mathematical Formulation
- Relationship to Surprise

**Learning Objectives:**
1. Calculate VFE

**Key Concepts:**
- Free Energy

**Rationale:** Central concept in variational inference.

---

## Module 7: Markov Models – Introduction & State Spaces

**Sessions**: 1

### Session 7: Markov Property

**Subtopics:**
- State Transitions
- Transition Probabilities

**Learning Objectives:**
1. Understand Markov transitions

**Key Concepts:**
- State Space

**Rationale:** Basis for dynamic models.

---

## Module 8: Probabilistic State-Space Models – Formulation

**Sessions**: 1

### Session 8: Model Equations

**Subtopics:**
- Continuous-Time Dynamics
- Sensory Input

**Learning Objectives:**
1. Understand model equations

**Key Concepts:**
- State Equations
- Measurement Equations

**Rationale:** Formalizing perception-action loops.

---

## Module 9: Precision Weighting & Attention

**Sessions**: 1

### Session 9: Weighting States

**Subtopics:**
- Precision of States

**Learning Objectives:**
1. Understand weighting

**Key Concepts:**
- Attention

**Rationale:** Mechanism for selective processing.

---

## Module 10: Predictive Coding – Neural Basis

**Sessions**: 1

### Session 10: Encoder-Decoder Model

**Subtopics:**
- Hierarchical Predictions

**Learning Objectives:**
1. Understand the predictive coding loop

**Key Concepts:**
- Error Signals

**Rationale:** Connecting theory to neuroscience.

---

## Module 11: Model Learning & Adaptation

**Sessions**: 1

### Session 11: Parameter Estimation

**Subtopics:**
- Maximum Likelihood Estimation

**Learning Objectives:**
1. Update model parameters

**Key Concepts:**
- Learning Rate

**Rationale:** Model learning is central to adaptation.

---

## Module 12: Reinforcement Learning – Policy Optimization

**Sessions**: 1

### Session 12: Markov Decision Processes

**Subtopics:**
- Reward Function
- Transition Probabilities

**Learning Objectives:**
1. Understand MDPs

**Key Concepts:**
- Policy

**Rationale:** Connects Bayesian inference to decision making.

---

## Module 13: Generative Models – Hierarchical Structures

**Sessions**: 1

### Session 13: Multi-Level Models

**Subtopics:**
- Recurrent Networks

**Learning Objectives:**
1. Understand complex models

**Key Concepts:**
- Latent Variables

**Rationale:** Modeling hierarchical relationships.

---

## Module 14: Model Selection & Validation

**Sessions**: 1

### Session 14: Cross-Validation

**Subtopics:**
- Hold-out Sets

**Learning Objectives:**
1. Assess model performance

**Key Concepts:**
- Performance Metrics

**Rationale:** Ensuring model robustness.

---

## Module 15: Applications & Future Directions

**Sessions**: 1

### Session 15: Concluding Remarks

**Subtopics:**
- Synthesis of Concepts
- Future Research

**Learning Objectives:**
1. Critical Thinking

**Key Concepts:**
- Open Questions

**Rationale:** Final overview and integration of concepts.

---
