

## Open Question 1: What are the emergent properties of diffusion models during iterative refinement?

Context: Diffusion models have revolutionized image generation, but the underlying mechanisms driving their creative potential remain partially understood. Specifically, research is needed to characterize the complex, non-linear transformations that occur during the iterative refinement stages – how do subtle changes in noise gradually build up coherent structures? This research aims to move beyond simply measuring loss functions and instead understand the intrinsic dynamics shaping the generated outputs.

## Open Question 2: How does the incorporation of causal inference techniques influence the robustness and interpretability of generative models?

Context: Traditional generative models often treat data as purely correlational, leading to vulnerabilities when faced with distributional shifts. Integrating causal inference methods – specifically, identifying and controlling for confounding variables – promises to create models that are less susceptible to spurious correlations and more robust to real-world variations. This research investigates how incorporating causal graph representations and interventions can improve both the predictive accuracy and the explainability of generative models.

## Open Question 3: What are the limitations of current methods for evaluating the "hallucination" risk in large language models during creative tasks?

Context: Large language models (LLMs) frequently exhibit "hallucinations" – generating factually incorrect or nonsensical outputs, particularly when prompted for creative content.  Existing metrics often fail to capture the nuanced nature of these errors, particularly concerning imaginative deviations from reality. Research is urgently needed to develop more robust evaluation methods that can effectively quantify the level of "creative license" versus outright fabrication, allowing for better control and more reliable generation of novel content.