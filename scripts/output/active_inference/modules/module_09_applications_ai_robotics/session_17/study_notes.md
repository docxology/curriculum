# Applications: AI & Robotics - Study Notes

## Key Concepts

## Applications: AI & Robotics – Representation Learning & Active Inference

**Representation Learning**: Representation learning is the process by which an AI system automatically learns useful features and patterns from raw data, rather than relying on manually engineered features. This allows the system to adapt and generalize more effectively to new situations. Instead of being told *what* to look for, the system discovers the relevant representations itself.

**Active Inference**: Active inference posits that intelligent agents don’t simply react to their environment but actively construct their understanding of it. This involves generating predictions about the world and then comparing those predictions to sensory input, using the discrepancy to drive action. It’s a fundamentally predictive process.

**Predictive Coding**: Predictive coding is a core mechanism within active inference. It describes how the brain (and by extension, intelligent systems) constantly makes predictions about the world and then updates its internal model based on the difference between those predictions and actual sensory input. This continual updating creates a dynamic representation of the environment. Think of it as a constant feedback loop – predict, compare, adjust.

**Bayesian Inference**: Bayesian inference is a statistical method used within active inference to quantify uncertainty. It allows the system to represent its beliefs about the world in terms of probabilities, updating these probabilities based on new evidence. The system doesn’t just know *that* something is true, it understands *how likely* it is to be true.

**Internal Models**: An internal model is a representation of the agent’s environment, constructed through active inference. This model includes assumptions about how the world works, the relationships between different elements, and the potential consequences of actions. The more accurate the internal model, the better the agent can predict and control its environment.

**Sensory Prediction Errors**: Sensory prediction errors are the discrepancies between the agent’s predicted sensory input and the actual sensory input it receives. These errors are the driving force behind active inference; they signal that the agent’s internal model needs to be updated. These errors aren't just noise; they're crucial information.

**Motor Prediction**: Motor prediction refers to the agent's ability to anticipate the sensory consequences of its own actions. This allows the agent to plan and execute actions that will achieve its goals, rather than simply reacting to external stimuli. The agent predicts *what will happen if I do this?*

**Causal Inference**: Causal inference, within the context of active inference, is the ability of an agent to determine the cause-and-effect relationships within its environment. This allows the agent to not only predict the consequences of its actions but also to actively shape its environment to achieve desired outcomes. It goes beyond simple prediction to understanding *why* things happen.

**Hierarchical Predictive Coding**: This describes how predictive coding is organized within the brain, with lower levels focusing on basic sensory predictions and higher levels integrating these predictions with more complex, abstract concepts. It represents a layered approach to understanding the world, enabling increasingly sophisticated predictions and control.

**Reinforcement Learning Integration**: Representation learning and active inference are often integrated with reinforcement learning, allowing agents to learn optimal actions not just based on reward signals, but also on their understanding of the underlying causal structure of the environment. It's a more robust and flexible approach to control.